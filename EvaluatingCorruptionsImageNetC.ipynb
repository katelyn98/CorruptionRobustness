{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvaluatingCorruptionsImageNetC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "j5Cwt-CYsna0",
        "kmo9nSRL_Bl_",
        "tzMNXNjx_G8Z"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katelyn98/CorruptionRobustness/blob/main/EvaluatingCorruptionsImageNetC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRgMcOkKXut0"
      },
      "source": [
        "## Install and import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63A3b3HX1zL8"
      },
      "source": [
        "!pip3 install timm\n",
        "!pip install pytorch_pretrained_vit\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import os\n",
        "from skimage import io\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import requests, zipfile, io\n",
        "import subprocess\n",
        "from pytorch_pretrained_vit import ViT\n",
        "import timm\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80oQSOokDyhR"
      },
      "source": [
        "## Download ImageNet-C\n",
        "Choose the class from ImageNet-c that you want to evaluate. Note: You should only do one class at a time or Google Colab will run out of space. \n",
        "\n",
        "Downloading ImageNet-C will take at least 10 minutes depending on the class you are downloading. \n",
        "\n",
        "**Note**: If you do not have Colab Pro, you may not be able to download some classes because of their size. Refer to the [original download site](https://zenodo.org/record/2235448#.YKqCy5NKjLY) for the size of each class.\n",
        "\n",
        "Another note: you can double click on the title of the form in google colab to see the code that is running the form. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJuNAMU1H-HW",
        "cellView": "form"
      },
      "source": [
        "#@title ImageNet-C Class to Evaluate\n",
        "\n",
        "dropdown = 'blur' #@param [\"blur\", \"weather\", \"noise\", \"extra\", \"digital\"]\n",
        "\n",
        "if dropdown == 'blur':\n",
        "  subprocess.run('wget \"https://zenodo.org/record/2235448/files/blur.tar?download=1\"; mv /content/blur.tar?download=1 /content/blur.tar; tar -xf blur.tar; rm -rf blur.tar; done', shell=True)\n",
        "elif dropdown == 'weather':\n",
        "  subprocess.run('wget \"https://zenodo.org/record/2235448/files/weather.tar?download=1\"; mv /content/weather.tar?download=1 /content/weather.tar; tar -xf weather.tar; rm -rf weather.tar; done', shell=True)\n",
        "elif dropdown == 'noise':\n",
        "  subprocess.run('wget \"https://zenodo.org/record/2235448/files/noise.tar?download=1\"; mv /content/noise.tar?download=1 /content/noise.tar; tar -xf noise.tar; rm -rf noise.tar; done', shell=True)\n",
        "elif dropdown == 'extra':\n",
        "  subprocess.run('wget \"https://zenodo.org/record/2235448/files/extra.tar?download=1\"; mv /content/extra.tar?download=1 /content/extra.tar; tar -xf extra.tar; rm -rf extra.tar; done', shell=True)\n",
        "elif dropdown == 'digital':\n",
        "  subprocess.run('wget \"https://zenodo.org/record/2235448/files/digital.tar?download=1\"; mv /content/digital.tar?download=1 /content/digital.tar; tar -xf digital.tar; rm -rf digital.tar; done', shell=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SruoiwE9XyHe"
      },
      "source": [
        "## Class to evaluate function\n",
        "Note: ImageNet-C has 1000 classes. You can modify this in the case of using CIFAR-10-C or CIFAR-100-C\n",
        "\n",
        "Note: Some models require differnt input size. You can modify the image size here to be the size your model requires."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtlizZbit06n"
      },
      "source": [
        "Below of the subclasses available for each corruption class. In the subclass spot, you must type the subclass exactly as shown below. \n",
        "\n",
        "**Blur**: 'defocus_blur', 'glass_blur', 'zoom_blur', 'motion_blur'\n",
        "\n",
        "**Weather**: 'frost', 'fog', 'snow', 'brightness'\n",
        "\n",
        "**Noise**: 'gaussian_noise', 'shot_noise', 'impulse_noise'\n",
        "\n",
        "**Digital**:  'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression'\n",
        "\n",
        "**Extra**: 'speckle_noise', 'spatter', 'gaussian_blur', 'saturate'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yF9rRO812Sq",
        "cellView": "form"
      },
      "source": [
        "#@title Choose subclass & create dataloader\n",
        "# # Number of classes in the dataset\n",
        "num_classes = 1000 #@param {type:\"integer\"}\n",
        "batch_size = 100 #@param {type:\"integer\"}\n",
        "# # Batch size for training (change depending on how much memory you have)\n",
        "\n",
        "subclass = 'motion_blur' #@param {type:\"string\"}\n",
        "\n",
        "if dropdown == 'blur':\n",
        "  if subclass != 'motion_blur' and subclass != 'zoom_blur' and subclass != 'glass_blur' and subclass != 'defocus_blur':\n",
        "    print(\"Please choose a subclass from the following:\")\n",
        "    print(\"['motion_blur', 'zoom_blur', 'defocus_blur', 'glass_blur']\")\n",
        "elif dropdown == 'weather':\n",
        "  if subclass != 'frost' and subclass != 'snow' and subclass != 'fog' and subclass != 'brightness':\n",
        "    print(\"Please choose a subclass from the following:\")\n",
        "    print(\"['frost', 'snow', 'fog', 'brightness']\")\n",
        "elif dropdown == 'noise':\n",
        "  if subclass != 'gaussian_noise' and subclass != 'shot_noise' and subclass != 'impulse_noise':\n",
        "    print(\"Please choose a subclass from the following:\")\n",
        "    print(\"['gaussian_noise', 'shot_noise', 'impulse_noise']\")\n",
        "elif dropdown == 'extra':\n",
        "  if subclass != 'speckle_noise' and subclass != 'spatter' and subclass != 'gaussian_blur' and subclass != 'saturate':\n",
        "    print(\"Please choose a subclass from the following:\")\n",
        "    print(\"['speckle_noise', 'spatter', 'gaussian_blur', 'saturate']\")\n",
        "elif dropdown == 'digital':\n",
        "  if subclass != 'contrast' and subclass != 'elastic_transform' and subclass != 'pixelate' and subclass != 'jpeg_compression':\n",
        "    print(\"Please choose a subclass from the following:\")\n",
        "    print(\"['contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']\")\n",
        "\n",
        "\n",
        "#change this to your directory of ImageNet-C images \n",
        "#for the specific class you are testing\n",
        "data_dir = \"/content/\"+subclass\n",
        "severity =  2#@param {type:\"integer\"}\n",
        "\n",
        "image_size = 254 #@param {type:\"integer\"}\n",
        "center_crop = 224 #@param {type:\"integer\"}\n",
        "\n",
        "key = str(severity)\n",
        "data_transforms = {\n",
        "    key: transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.CenterCrop(center_crop),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Create dataset\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in [key]}\n",
        "# Create dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in [key]}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrzdO5yjW4Km"
      },
      "source": [
        "## Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I_mGA0TW6aT"
      },
      "source": [
        "def evaluation(model, dataloaders, key):\n",
        "  #switch model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    right, running_total = 0, 0\n",
        "    \n",
        "    for inputs, labels in dataloaders[key]:\n",
        "      images = inputs.to('cuda:0')\n",
        "      ground_truth = labels.to('cuda:0')\n",
        "\n",
        "      output_probs = model(images) #pass images through model to get probability for each class (1 x 10 dim)\n",
        "      _, pred_label = torch.max(output_probs.data, 1) #returning index (also label id) for col with highest prediction in the 1 x 10 vector output_preds\n",
        "\n",
        "      running_total += ground_truth.size(0) #keep track of the number of labels\n",
        "      right += (pred_label == ground_truth).sum().item() #keeping track number of correct predictions\n",
        "\n",
        "  acc = (right / running_total)  \n",
        "  print('Accuracy is ' + str(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njCnCcJxVXTy"
      },
      "source": [
        "# Evaluation on ImageNet-C "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIy4iZmLRj-S",
        "cellView": "form"
      },
      "source": [
        "#@title Choose your model to evaluate\n",
        "\n",
        "model_choice = \"ViT\" #@param [\"ViT\", \"CaiT\", \"DeiT\", \"Swin-T\", \"MLP-Mixer\", \"ResNet50\", \"AlexNet\", \"VGG\", \"GoogLeNet\"]\n",
        "\n",
        "exact_model = \"ViT_L16\" #@param [\"ViT_B16\", \"ViT_L16\", \"DeiT_B16\", \"DeiT_B16_Distilled\", \"DeiT_S16\", \"DeiT_S16_Distilled\", \"DeiT_T16\", \"DeiT_T16_Distilled\", \"CaiT_S24\", \"CaiT_XXS24\", \"Swin-T_B\", \"Swin-T_L\", \"Swin-T_S\", \"Swin-T_T\", \"mixer_b16\", \"mixer_l16\", \"ResNet50\", \"AlexNet\", \"VGG16\", \"GoogLeNet\"]\n",
        "\n",
        "if exact_model == 'ViT_B16':\n",
        "  if model_choice != \"ViT\":\n",
        "    print(\"please set model_choice to 'ViT'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_base_patch16_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('vit_base_patch16_384', pretrained=True)\n",
        "      print(\"Using model vit_base_patch16_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'ViT_L16':\n",
        "  if model_choice != \"ViT\":\n",
        "    print(\"please set model_choice to 'ViT'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_large_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_large_patch16_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('vit_large_patch16_384', pretrained=True)\n",
        "      print(\"Using model vit_large_patch16_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'DeiT_B16':\n",
        "  if model_choice != \"DeiT\":\n",
        "    print(\"please set model_choice to 'DeiT'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_base_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_deit_base_patch16_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('vit_deit_base_patch16_384', pretrained=True)\n",
        "      print(\"Using model vit_deit_base_patch16_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "elif exact_model == \"DeiT_B16_Distilled\":\n",
        "  if model_choice != \"DeiT\":\n",
        "    print(\"please set model_choice to 'DeiT'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_base_distilled_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_deit_base_distilled_patch16_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('vit_deit_base_distilled_patch16_384', pretrained=True)\n",
        "      print(\"Using model vit_deit_base_distilled_patch16_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "elif exact_model == 'DeiT_S16':\n",
        "  if model_choice != \"DeiT\":\n",
        "    print(\"please set model_choice to 'DeiT'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_small_patch16_224', pretrained = True)\n",
        "      print(\"Using model vit_deit_small_patch16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "elif exact_model == 'DeiT_S16_Distilled':\n",
        "  if model_choice != \"DeiT\":\n",
        "    print(\"please set model_choice to 'DeiT'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_small_distilled_patch16_224', pretrained = True)\n",
        "      print(\"Using model vit_deit_small_distilled_patch16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "elif exact_model == 'DeiT_T16':\n",
        "  if model_choice != \"DeiT\":\n",
        "    print(\"please set model_choice to 'DeiT'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_tiny_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_deit_tiny_patch16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "elif exact_model == 'DeiT_T16_Distilled':\n",
        "  if model_choice != \"DeiT\":\n",
        "    print(\"please set model_choice to 'DeiT'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_tiny_distilled_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_deit_tiny_distilled_patch16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'CaiT_S24':\n",
        "  if model_choice != \"CaiT\":\n",
        "    print(\"please set model_choice to 'CaiT'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('cait_s24_224', pretrained=True)\n",
        "      print(\"Using model cait_s24_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('cait_s24_384', pretrained=True)\n",
        "      print(\"Using model cait_s24_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'CaiT_XXS24':\n",
        "  if model_choice != \"CaiT\":\n",
        "    print(\"please set model_choice to 'CaiT'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('cait_xxs24_224', pretrained=True)\n",
        "      print(\"Using model cait_xxs24_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('cait_xxs24_384', pretrained=True)\n",
        "      print(\"Using model cait_xxs24_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'Swin-T_B':\n",
        "  if model_choice != \"Swin-T\":\n",
        "    print(\"please set model_choice to 'Swin-T'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
        "      print(\"Using model swin_base_patch4_window7_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('swin_base_patch4_window7_384', pretrained=True)\n",
        "      print(\"Using model swin_base_patch4_window7_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'Swin-T_L':\n",
        "  if model_choice != \"Swin-T\":\n",
        "    print(\"please set model_choice to 'Swin-T'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('swin_large_patch4_window7_224', pretrained=True)\n",
        "      print(\"Using model swin_large_patch4_window7_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('swin_large_patch4_window7_384', pretrained=True)\n",
        "      print(\"Using model swin_large_patch4_window7_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'Swin-T_S':\n",
        "  if model_choice != \"Swin-T\":\n",
        "    print(\"please set model_choice to 'Swin-T'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('swin_small_patch4_window7_224', pretrained=True)\n",
        "      print(\"Using model swin_small_patch4_window7_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'Swin-T_T':\n",
        "  if model_choice != \"Swin-T\":\n",
        "    print(\"please set model_choice to 'Swin-T'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)\n",
        "      print(\"Using model swin_tiny_patch4_window7_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'mixer_b16':\n",
        "  if model_choice != \"MLP-Mixer\":\n",
        "    print(\"please set model_choice to 'MLP-Mixer'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('mixer_b16_224', pretrained=True)\n",
        "      print(\"Using model mixer_b16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'mixer_l16':\n",
        "  if model_choice != \"MLP-Mixer\":\n",
        "    print(\"please set model_choice to 'MLP-Mixer'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('mixer_l16_224', pretrained=True)\n",
        "      print(\"Using model mixer_l16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'AlexNet':\n",
        "  if model_choice != \"AlexNet\":\n",
        "    print(\"please set model_choice to 'AlexNet'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = models.alexnet(pretrained=True)\n",
        "      print(\"Using model AlexNet\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'ResNet50':\n",
        "  if model_choice != \"ResNet50\":\n",
        "    print(\"please set model_choice to 'ResNet50'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = models.resnet50(pretrained=True)\n",
        "      print(\"Using model ResNet50\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'GoogLeNet':\n",
        "  if model_choice != \"GoogLeNet\":\n",
        "    print(\"please set model_choice to 'GoogLeNet'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = models.googlenet(pretrained=True)\n",
        "      print(\"Using model GoogLeNet\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "elif exact_model == 'VGG16':\n",
        "  if model_choice != \"VGG16\":\n",
        "    print(\"please set model_choice to 'VGG16'\")\n",
        "  else:\n",
        "    if center_crop == 224:\n",
        "      model = models.vgg16(pretrained=True)\n",
        "      print(\"Using model VGG16\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "model = model.to('cuda:0')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYkGWR2bcWUS"
      },
      "source": [
        " **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txfF4prVcX9z"
      },
      "source": [
        "print(\"SEVERITY of \" + str(severity))\n",
        "print(\"CLASS: \" + str(dropdown) + \" - \" + str(subclass))\n",
        "evaluation(model, dataloaders_dict, key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5Cwt-CYsna0"
      },
      "source": [
        "## Run all models at once"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmo9nSRL_Bl_"
      },
      "source": [
        "### Model Choice function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3pnSS0uuDm_"
      },
      "source": [
        "\n",
        "def model_choice(exact_model_usr):\n",
        "\n",
        "  exact_model = exact_model_usr\n",
        "\n",
        "  if exact_model == 'ViT_B16':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_base_patch16_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('vit_base_patch16_384', pretrained=True)\n",
        "      print(\"Using model vit_base_patch16_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'ViT_L16':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_large_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_large_patch16_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('vit_large_patch16_384', pretrained=True)\n",
        "      print(\"Using model vit_large_patch16_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'DeiT_B16':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_base_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_deit_base_patch16_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('vit_deit_base_patch16_384', pretrained=True)\n",
        "      print(\"Using model vit_deit_base_patch16_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "  elif exact_model == \"DeiT_B16_Distilled\":\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_base_distilled_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_deit_base_distilled_patch16_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('vit_deit_base_distilled_patch16_384', pretrained=True)\n",
        "      print(\"Using model vit_deit_base_distilled_patch16_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "  elif exact_model == 'DeiT_S16':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_small_patch16_224', pretrained = True)\n",
        "      print(\"Using model vit_deit_small_patch16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "  elif exact_model == 'DeiT_S16_Distilled':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_small_distilled_patch16_224', pretrained = True)\n",
        "      print(\"Using model vit_deit_small_distilled_patch16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "  elif exact_model == 'DeiT_T16':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_tiny_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_deit_tiny_patch16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "  elif exact_model == 'DeiT_T16_Distilled':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('vit_deit_tiny_distilled_patch16_224', pretrained=True)\n",
        "      print(\"Using model vit_deit_tiny_distilled_patch16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'CaiT_S24':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('cait_s24_224', pretrained=True)\n",
        "      print(\"Using model cait_s24_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('cait_s24_384', pretrained=True)\n",
        "      print(\"Using model cait_s24_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'CaiT_XXS24':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('cait_xxs24_224', pretrained=True)\n",
        "      print(\"Using model cait_xxs24_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('cait_xxs24_384', pretrained=True)\n",
        "      print(\"Using model cait_xxs24_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'Swin-T_B':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
        "      print(\"Using model swin_base_patch4_window7_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('swin_base_patch4_window7_384', pretrained=True)\n",
        "      print(\"Using model swin_base_patch4_window7_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'Swin-T_L':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('swin_large_patch4_window7_224', pretrained=True)\n",
        "      print(\"Using model swin_large_patch4_window7_224\")\n",
        "    elif center_crop == 384:\n",
        "      model = timm.create_model('swin_large_patch4_window7_384', pretrained=True)\n",
        "      print(\"Using model swin_large_patch4_window7_384\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'Swin-T_S':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('swin_small_patch4_window7_224', pretrained=True)\n",
        "      print(\"Using model swin_small_patch4_window7_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'Swin-T_T':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)\n",
        "      print(\"Using model swin_tiny_patch4_window7_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'mixer_b16':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('mixer_b16_224', pretrained=True)\n",
        "      print(\"Using model mixer_b16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'mixer_l16':\n",
        "    if center_crop == 224:\n",
        "      model = timm.create_model('mixer_l16_224', pretrained=True)\n",
        "      print(\"Using model mixer_l16_224\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'AlexNet':\n",
        "    if center_crop == 224:\n",
        "      model = models.alexnet(pretrained=True)\n",
        "      print(\"Using model AlexNet\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'ResNet50':\n",
        "    if center_crop == 224:\n",
        "      model = models.resnet50(pretrained=True)\n",
        "      print(\"Using model ResNet50\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'GoogLeNet':\n",
        "    if center_crop == 224:\n",
        "      model = models.googlenet(pretrained=True)\n",
        "      print(\"Using model GoogLeNet\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  elif exact_model == 'VGG16':\n",
        "    if center_crop == 224:\n",
        "      model = models.vgg16(pretrained=True)\n",
        "      print(\"Using model VGG16\")\n",
        "    else:\n",
        "      print(\"image size wrong\")\n",
        "\n",
        "  model = model.to('cuda:0')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzMNXNjx_G8Z"
      },
      "source": [
        "### Loop through all models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buSmKsO2spjo"
      },
      "source": [
        "modellist = [\"ViT_B16\", \"ViT_L16\", \"DeiT_B16\", \"DeiT_B16_Distilled\", \"DeiT_S16\", \"DeiT_S16_Distilled\", \"DeiT_T16\", \"DeiT_T16_Distilled\", \"CaiT_S24\", \"CaiT_XXS24\", \"Swin-T_B\", \"Swin-T_L\", \"Swin-T_S\", \"Swin-T_T\", \"mixer_b16\", \"mixer_l16\", \"ResNet50\", \"AlexNet\", \"VGG16\", \"GoogLeNet\"]\n",
        "\n",
        "for modelname in modellist:\n",
        "  model = model_choice(modelname)\n",
        "\n",
        "  print(\"SEVERITY of \" + str(severity))\n",
        "  print(\"CLASS: \" + str(dropdown) + \" - \" + str(subclass))\n",
        "  evaluation(model, dataloaders_dict, key)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}